\title{Assignment 4: CS 763, Computer Vision}
\author{}
\date{Due 29th March before 11:55 pm}

\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{ulem}
\usepackage[margin=0.5in]{geometry}
\begin{document}
\maketitle

\textbf{Remember the honor code while submitting this (and every other) assignment. You may discuss broad ideas with other student groups or ask me for any difficulties, but the code you implement and the answers you write must be from members of the group. We will adopt a \textbf{zero-tolerance policy} against any violation.}
\\
\\
\textbf{Submission instructions:} You should ideally type out all the answers in Word (with the equation editor) or using Latex. In either case, prepare a pdf file. Put the pdf file and the code for the programming parts all in one zip file. The pdf file should contain instructions for running your code. Name the zip file as follows: A4-IdNumberOfFirstStudent-IdNumberOfSecondStudent.zip. If you are doing the assignment alone, the name of the zip file should be A4-IdNumber.zip. Late assignments will be assessed a penalty of 50\% per day late. Please preserve a copy of all your work until the end of the semester. 

\begin{enumerate}
\item In this exercise, you will implement the Adaboost method for creating a strong binary classifier from a series of weaker classifiers. You will work with some synthetic datasets and also with the MNIST dataset containing images of digits.
\\
Consider a training set consisting of $N$ input vectors $\{\textbf{x}_j\}_{j=1}^{N}$ in a $d$-dimensional space, and their respective labels $\{y_j\}_{j=1}^N$ where $\forall j, y_j \in \{-1,+1\}$. You will assign a scalar weight to each input vector. Before the first iteration of Adaboost, these weights will be set to be equal in value. In each round $t$, you will pick the best classifier from the following family of weak classifiers: $h_t(\textbf{x}; i,p,\theta) = \textrm{sign}(p(x_i - \theta))$ where $x_i$ is the $i^{\textrm{th}}$ element of $d$-dimensional input vector $\textbf{x}$, the parameter $p \in \{-1,+1\}$ and $\theta$ is a real-valued threshold parameter. Basically, this classifier assigns input vector $\textbf{x}$ the label `+1' if either (1) $x_i > \theta$ and $p = +1$, or (2) $x_i \leq \theta$ and $p=-1$. Otherwise it assigns $\textbf{x}$ the label `-1'. The best classifier refers to the classifier producing the least weighted error on the training set, i.e. least value of $\epsilon = \sum_{j=1}^N w_j I(h_t(\textbf{x}_j) \neq y_j)$ where $I(.)$ is an indicator function that returns 1 if the predicate passed as a parameter is true, and returns 0 otherwise. Note that the search for the best classifiers involves picking the tuple $(i,p,\theta)$. After picking the best classifier, you will update the weights following the method in the standard Adaboost algorithm. This entire process is repeated for $T$ rounds. You need to specify the value of $T$ but $T = 30$ to $40$ is sufficient. The final classifier after $T$ rounds will have the form $H(\textbf{x}) = \textrm{sign}(\sum_{t=1}^{T} \alpha_t h_t(\textbf{x}))$. 
\\
You will work with the following datasets. 
\begin{enumerate}
\item A dataset containing 2000 points in 2D drawn from a [0,1] bounded uniform random distribution. Label all the points lying on or inside a rectangle bounded by the lines $x = 0.3$, $x = 0.7$, $y = 0.3$, $y= 0.7$ as $+1$ and the rest as $-1$. Randomly divide this dataset into disjoint sets of 1000 training points and 1000 test points (called dataset1). 
\item A dataset containing 2000 points in 2D drawn from a [0,1] bounded uniform random distribution. Label all the points satisfying any of the following conditions as `+1' and the rest as `-1': (1) lying on or inside a rectangle bounded by the lines $x = 0.3$, $x = 0.7$, $y = 0.3$, $y= 0.7$ as $+1$ , (2) with x-coordinate between 0.15 and 0.25 or between 0.75 and 0.85, (3) with y-coordinate between 0.15 and 0.25 or between 0.75 and 0.85. Randomly divide this dataset into disjoint sets of 1000 training points and 1000 test points (called dataset2). 
\item A dataset containing 2000 points in 2D drawn from a zero-mean Gaussian distribution of standard deviation 2. Label all the points whose distance from the origin is less than 2 as +1 and the rest as -1. Randomly divide this dataset into disjoint sets of 1000 training points and 1000 test points (called dataset3). 
\item A dataset containing 2000 points in 2D drawn from a zero-mean Gaussian distribution of standard deviation 2. Label all the points whose distance from the origin is either less than 2, or between 2.5 and 3, as +1 and the rest as -1. Randomly divide this dataset into disjoint sets of 1000 training points and 1000 test points (called dataset4). 
\item The MNIST database is a popular dataset containing images of handwritten digits from 0 to 9. It can be downloaded from \url{http://yann.lecun.com/exdb/mnist/}. The dataset contains four files each in `idx' format, namely train-images-idx3-ubyte.gz which contains the training data consisting of 60000 images of size 28 by 28 each, train-labels-idx1-ubyte.gz which contains the respective labels of the training images, t10k-images-idx3-ubyte.gz which contains 10000 images of size 28 by 28 each for testing, with their respective labels (for ground truth) marked out in t10k-labels-idx1-ubyte.gz. A MATLAB script for reading these files into memory is uploaded here: \url{https://www.cse.iitb.ac.in/~ajitvr/CS763_Spring2016/HW4/readMNIST.m}. You will need to gunzip each of the four files before calling this (parameter-free) function readMNIST. You should perform training on the first 5000 images from the training set. Label the images belonging to the digit `2' as `+1' and all the others as `-1'. Thus for this database, your job is to determine whether a given image contains the selected digit `2' or not.
\end{enumerate}
For each of the five datasets, do the following after each round of Adaboost: (1) estimate and print the training error of the \emph{strong} classifier created thus far, (2) estimate and print the error of the \emph{strong} classifier created thus far on the \emph{test} set. For the first four datasets, also plot the test points with their associated labels using the MATLAB function called `scatter' (in each round of Adaboost). Sample scatter plots for the first four datasets can be found at  \url{http://www.cse.iitb.ac.in/~ajitvr/CS763_Spring2016/HW4/} (named as dataset1.jpg and so on). You do not need to include the scatter plot images from each iteration in your report. Finally, for all five datasets, plot a graph of the test set error versus the number of rounds of Adaboost and include it in your report. Do you notice something peculiar with the fourth dataset? Explain what you would you do to remedy that situation (there is no need to implement). 
\textsf{[4+4+4+4+10+4 = 30 points]}

\item In this exercise, we will see a beautiful application: recovering the structure of a wavy water surface under the influence of wind (under certain assumptions), and also reconstructing a distortion-free image of any objects under the water surface. To this end, consider a water-tank with a still, perfectly horizontal water surface of height $h_0$ above the tank-floor (= XY plane). A ray of light $\mathbf{s} = (0,0,-1)$ hits the water surface at point $P$ and goes through without refraction striking the tank-floor at point $Q$. However, usually, the water surface is wavy (say, due to wind) and will not have a constant height. We will denote the height and surface normal at any surface point as $h(x,y)$ and $\mathbf{n}(x,y) = (n_x(x,y),n_y(x,y),n_z(x,y))$ respectively.  The ray $\mathbf{s}$ will now get refracted at $P$ and strike the tank-floor at point $Q' \neq Q$. Let $\mathbf{r}$ be the refracted ray, $\alpha$ be the angle of incidence, i.e. angle between $\mathbf{n}$ and $\mathbf{s}$, and $\beta$ be the angle of refraction, i.e. angle between $\mathbf{n}$ and $\mathbf{r}$. We know that (a) $\mathbf{r}$ lies in the plane spanned by $\mathbf{s}$ and $\mathbf{n}$, and that (b) $\frac{\sin \alpha}{\sin \beta} = \textrm{refractive index of water} = \kappa$. We will assume that the water surface acts as a purely transparent surface and that there are no reflections or specularities (this is a simplifying assumption that is not valid in many real-life scenarios). Draw a simple ray diagram and answer the following:
\begin{enumerate}
\item Write the mathematical relation between $\mathbf{n}(x,y)$ and $h(x,y)$.
\item Let $\mathbf{r}_x$ and $\mathbf{r}_y$ be the $x$ and $y$ components of the vector $\mathbf{r}$. Prove that $(\mathbf{r}_x,\mathbf{r}_y)$ is parallel to $(\dfrac{\partial h}{\partial x},\dfrac{\partial h}{\partial y})$.
\item Express the magnitude of vector $QQ'$ in terms of $\alpha$, $\beta$ and $h_0$. What is the relation between $QQ'$ and $\mathbf{r}$?
\item Now, let us assume that the water surface fluctuations are very small. Hence $\alpha$, $\beta$ and change in height are very small. Use this to prove that $(\mathbf{r}_x,\mathbf{r}_y) = h_0(1-1/\kappa)(\dfrac{\partial h}{\partial x},\dfrac{\partial h}{\partial y})$.
\item Now, given the video of a static scene on the tank floor beneath a wavy water surface undergoing small fluctuations, suggest a method to recover $h(x,y)$ at any time time instant. You may assume that the height at any point averaged over time is $h_0$. \textsf{[3 + 3 + 4 + 4 + 6 = 20 points]}
\end{enumerate}
Useful formulae: $\sin(A+B) = \sin A \cos B + \cos A \sin B; \cos(A+B) = \cos A \cos B - \sin A \sin B; \tan (A+B) = \frac{\tan A + \tan B}{1 - \tan A \tan B}; \tan(A-B) = \frac{\tan A - \tan B}{1 + \tan A \tan B}$. For small $A$, $\sin A \approx \tan A$.

\end{enumerate}
\end{document}